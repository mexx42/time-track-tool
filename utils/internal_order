#!/usr/bin/env python

from __future__ import print_function
import os
import re
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning

from csv      import DictReader
from roundup  import instance
from argparse import ArgumentParser
from netrc    import netrc
from bs4      import BeautifulSoup

try :
    from urllib.parse import urlunparse, quote
except ImportError :
    from urlparse import urlunparse
    from urllib   import quote

class Importer (object) :

    def __init__ (self, args) :
        self.args = args
        self._url = None
        tracker   = instance.open (args.dir)
        self.db   = tracker.open (args.user)
        self.f_in = None
        self.chk  = not self.args.no_check_certificate
        if not self.chk :
            requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
    # end def __init__

    def get_latest_export_url (self) :
        """ The URL given is a directory url of an apache directory listing.
            We search through all files in that directory and return the URL
            which contains the latest file. The format of the filenames we
            search for is prefix + YYYYmmddHHMMSS + suffix.
            For this we simply search for all the hrefs matching the
            pattern. We sort these by name (the date format above is
            sortable) and return the latest and greatest.
        """
        ans  = requests.get (self.url, verify = self.chk)
        if not (200 <= ans.status_code <= 299) :
            raise RuntimeError \
                ( 'Invalid get result: %s: %s\n    %s'
                , (ans.status_code, ans.reason, ans.text)
                )
        soup = BeautifulSoup (ans.text, 'html.parser')
        res  = []
        for a in soup.find_all ('a') :
            href = a.get ('href')
            if not href.startswith (self.args.prefix) :
                continue
            if not href.endswith (self.args.suffix) :
                continue
            res.append (href)
        res.sort ()
        if res :
            return res [-1]
    # end def get_latest_export_url

    def importer (self) :
        r  = DictReader (self.f_in, delimiter = self.args.delimiter)
        st = 'Internal Order: Statistical orders'

        for line in r :
            if line ['T003P~TXT'].decode (self.args.encoding) != st :
                continue
            if line ['AUFK~AUFNR'] :
                num  = str \
                    (int (line ['AUFK~AUFNR'].decode (self.args.encoding)))
                name = line ['AUFK~KTEXT'].decode (self.args.encoding)

                try :
                    id = self.db.internal_order.lookup (num.encode ('utf-8'))
                    io = self.db.internal_order.getnode (id)
                    d  = {}
                    if not io.valid :
                        d ['valid'] = True
                    if name and io.name != name.encode ('utf-8') :
                        d ['name'] = name.encode ('utf-8')
                    if d :
                        if self.args.update :
                            self.db.internal_order.set (id, **d)
                        if self.args.verbose :
                            print ( "Updating internal_order%s (%s): %s"
                                  % (id, io.order_number, d)
                                  )
                except KeyError :
                    if self.args.update :
                        self.db.internal_order.create \
                            ( order_number = num.encode ('utf-8')
                            , name         = name.encode ('utf-8')
                            , valid        = True
                            )
                    if self.args.verbose :
                        print ("Creating %s: %s" % (num, name))

        if self.args.update :
            self.db.commit ()
    # end importer

    def open (self) :
        if self.args.file :
            self.f_in = open (self.args.file, 'r')
        else :
            fn  = self.get_latest_export_url ()
            url = '/'.join ((self.url, fn))
            gr  = requests.get (url, verify = self.chk)
            self.f_in = gr.iter_lines ()
    # end def open

    def run (self) :
        self.open     ()
        self.importer ()
    # end def run

    @property
    def url (self) :
        if self._url :
            return self._url
        username = ''
        password = ''
        a = n = None
        try :
            n = netrc ()
        except IOError :
            pass
        if n and self.args.hostname :
            a = n.authenticators (self.args.hostname)
        if a :
            un, d, pw = a
            username = un
            password = pw
        un = ''
        if username :
            un = [username]
            if password :
                un.append (':')
                un.append (quote (password))
            un.append ('@')
            un = ''.join (un)
        netloc = []
        if un :
            netloc.append (un)
        netloc.append (self.args.hostname)
        if self.args.port :
            netloc.append (':')
            netloc.append (self.args.port)
        netloc = ''.join (netloc)
        self._url = urlunparse \
            ((self.args.scheme, netloc, self.args.path, '', '', ''))
        return self._url
    # end def url

# end class Importer

def main () :
    cmd = ArgumentParser ()
    cmd.add_argument \
        ( '-d', '--directory'
        , dest    = 'dir'
        , help    = 'Tracker instance directory default: "%(default)s"'
        , default = '.'
        )
    cmd.add_argument \
        ( '-C', '--no-check-certificate'
        , help    = 'Do not check issuer certificate for https url'
        , action  = 'store_true'
        )
    cmd.add_argument \
        ( '-D', '--delimiter'
        , dest    = 'delimiter'
        , help    = 'CSV delimiter character default: "%(default)s"'
        , default = ';'
        )
    cmd.add_argument \
        ( '-E', '--encoding'
        , dest    = 'encoding'
        , help    = 'CSV encoding default: %(default)s'
        , default = 'utf-8'
        )
    cmd.add_argument \
        ( "-n", "--hostname"
        , help    = "URL for data download, default=%(default)s"
        , default = "data-export.vie.at.tttech.ttt"
        )
    cmd.add_argument \
        ( "-P", "--port"
        , help    = '"Port for retrieving file, default="%(default)s"'
        , default = ""
        )
    cmd.add_argument \
        ( "-p", "--path"
        , help    = "Directory component of URL for data download, "
                    "default=%(default)s"
        , default = "/sap-export/erp-productive/masterdata/IAUF"
        )
    cmd.add_argument \
        ( "--prefix"
        , help    = "Filename prefix on remote storage, default=%(default)s"
        , default = "IAUF_"
        )
    cmd.add_argument \
        ( "-s", "--scheme"
        , help    = "URL schem for retrieving file, default=%(default)s"
        , default = "http"
        )
    cmd.add_argument \
        ( "--suffix"
        , help    = "Filename suffix on remote storage, default=%(default)s"
        , default = ".CSV"
        )
    cmd.add_argument \
        ( "-u", "--user"
        , help    = "User to open the tracker as (%(default)s)"
        , default = 'admin'
        )
    cmd.add_argument \
        ( "-U", "--update"
        , help    = "Really update the database"
        , action  = 'store_true'
        , default = False
        )
    cmd.add_argument \
        ( "-V", "--verbose"
        , help    = "Verbose output"
        , action  = 'store_true'
        , default = False
        )
    cmd.add_argument \
        ( "file"
        , help    = "Optional name of the CSV export file"
                    " -- we're using the URL to retrieve the file if not given"
        , nargs   = '?'
        )
    args = cmd.parse_args ()

    impo = Importer (args)
    impo.run ()

# end def main

if __name__ == '__main__' :
    main ()
